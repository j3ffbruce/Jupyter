{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d65f57e-f8ba-49b9-839c-8c602106d91a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf4caf-8da9-4141-bcbe-54f82c6ff73f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Spark: Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e935e53-79bf-4515-b679-d4c9a50d88ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"session\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f045eebb-45e6-4d3e-8e48-df59d3b04883",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Spark: File reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51505e-7eea-4282-ab38-d0a37ca615cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ▪️ Reading text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbe55e4f-91f7-4e3c-8f4a-e795b3536c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+----+--------------------------------------+-----------+----+----+-----+-----+\n",
      "|line|original_data                         |agent      |abbr|S   |I    |R    |\n",
      "+----+--------------------------------------+-----------+----+----+-----+-----+\n",
      "|1   |\\nAmpicillin\\tAMP\\t<=8\\t16\\t>=32      |Ampicillin |AMP |<=8 |16   |>=32 |\n",
      "|2   |\\nCefotetan\\tCTT\\t<=16\\t32\\t>=64      |Cefotetan  |CTT |<=16|32   |>=64 |\n",
      "|3   |\\nCefdinir\\tCFD\\t<=1\\t2\\t>=4          |Cefdinir   |CFD |<=1 |2    |>=4  |\n",
      "|4   |\\nErtapenem\\tERT\\t<=2\\t4\\t>=8         |Ertapenem  |ERT |<=2 |4    |>=8  |\n",
      "|5   |\\nTicarcillin\\tTIC\\t<=16\\t32-64\\t>=128|Ticarcillin|TIC |<=16|32-64|>=128|\n",
      "+----+--------------------------------------+-----------+----+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"session\").getOrCreate()\n",
    "\n",
    "#Efetuando leitura dos Dados\n",
    "dataframe_file_txt = spark.read.text(\"./datasets/sample_dataset_antibiotics.txt\", lineSep=\"\\r\")\n",
    "\n",
    "#Exibindo Schema\n",
    "dataframe_file_txt.printSchema()\n",
    "\n",
    "# Efetua Transformação dos Dados \n",
    "dataframe_transform = dataframe_file_txt.withColumn(\n",
    "    \"line\",\n",
    "    function.monotonically_increasing_id()\n",
    ").filter(\n",
    "    function.col(\"line\") > 0\n",
    ").select(\n",
    "     function.col(\"line\").cast(\"integer\")\n",
    "    ,function.col(\"value\").alias(\"original_data\")\n",
    "    ,function.regexp_replace(function.split(function.col(\"value\"), \"\\t\")[0],\"\\n\", \"\").cast(\"string\").alias(\"agent\")\n",
    "    ,function.split(function.col(\"value\"), \"\\t\")[1].cast(\"string\").alias(\"abbr\")\n",
    "    ,function.split(function.col(\"value\"), \"\\t\")[2].cast(\"string\").alias(\"S\")\n",
    "    ,function.split(function.col(\"value\"), \"\\t\")[3].cast(\"string\").alias(\"I\")\n",
    "    ,function.split(function.col(\"value\"), \"\\t\")[4].cast(\"string\").alias(\"R\")\n",
    ")\n",
    "\n",
    "# Criação da Estrutura de Dados\n",
    "struct = StructType([\n",
    "     StructField(\"line\", IntegerType(), nullable=False)\n",
    "    ,StructField(\"original_data\", StringType(), nullable=False)\n",
    "    ,StructField(\"agent\", StringType(), nullable=False)\n",
    "    ,StructField(\"abbr\", StringType(), nullable=False)\n",
    "    ,StructField(\"S\", StringType(), nullable=False)\n",
    "    ,StructField(\"I\", StringType(), nullable=False)\n",
    "    ,StructField(\"R\", StringType(), nullable=False)\n",
    "])\n",
    "\n",
    "# Criação do Dataframe com os Dados Estruturados\n",
    "dataframe_antibiotics = spark.createDataFrame(data=dataframe_transform.rdd, schema=struct)\n",
    "\n",
    "# Visualização dos Dados\n",
    "dataframe_antibiotics.show(truncate=False,vertical=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187ab50-a39d-4531-a60b-f60c389133e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Definindo Schema do Dataset\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "#Efetuando Leitura dos Dados\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "#Salvando DataFrame em Memoria\n",
    "dataFrameCSV.cache()\n",
    "\n",
    "#Salvando DataFrame em Disco\n",
    "dataFrameCSV.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33558ca4-4605-41ca-a256-448819081f9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Spark: Criando Dataframe\n",
    "*- Cria uma Dataframe manualmente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31faf386-a8d3-4683-badf-4fff910a379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "# Estrutura de Dados\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "# Definição do Schema\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "#Criação do Dataframe\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "\n",
    "#Exibição do Schema\n",
    "df.printSchema()\n",
    "\n",
    "#Exibição dos Dados\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9d6af-c5b6-4d76-bb51-331d9c0f308c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Spark: Criando uma VIEW\n",
    "*- Cria uma view com base em um Dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad65f9-e1ba-4ae8-92a9-d72d556f5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "df_test = dataFrameCSV.select('kms_driven','owner').limit(10)\n",
    "\n",
    "#Cria View no Spark\n",
    "df_test.createOrReplaceTempView(\"df_test\")\n",
    "\n",
    "#Executa Consulta Usando SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    DATE_FORMAT(NOW(),'dd/MM/yyyy hh:ss') AS dt_atual, \n",
    "    kms_driven \n",
    "    FROM df_test\"\"\"\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef52550-8e05-4355-9a6f-f5f645ca02cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Spark: Listando Tabelas do Spark\n",
    "*- Lista todas as tabelas catalogadas no Spark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e1793-f53e-43b7-8f6b-ef597a82d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "df_test = dataFrameCSV.select('kms_driven','owner').limit(10)\n",
    "\n",
    "#Cria View no Spark\n",
    "df_test.createOrReplaceTempView(\"df_test\")\n",
    "\n",
    "#Lista Tabelas do Catálogo do Spark\n",
    "tbls = spark.catalog.listTables()\n",
    "print(tbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5f6f4-da10-4c6d-8948-ec487b9d39f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Spark: Adicionando Colunas ao DataFrame\n",
    "*- Adiciona 1 ou N colunas em um DF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515ea7f-34a0-4028-8936-141f6c90b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "#Adiciona Coluna\n",
    "dataFrameCSV_NewColumn = dataFrameCSV \\\n",
    "                        .withColumn(\"name_new1\",dataFrameCSV[\"name\"])\\\n",
    "                        .withColumn(\"name_new2\",dataFrameCSV[\"name\"])\n",
    "\n",
    "dataFrameCSV_NewColumn \\\n",
    ".select(\"name\", \"name_new1\", \"name_new2\")\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34498beb-d8bf-48c2-8d91-803cb61c1804",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Spark: Deletando Dataframe\n",
    "*- Apagando Estrutura de Dados (DataFrame)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27778fb9-ad50-4e6d-8726-94fcb562b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "#Remove Dataframe\n",
    "del dataFrameCSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b718b93-d789-4c60-a7ac-57618f16d61d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: Select (*)\n",
    "\n",
    "*- Seleção de todos os valores de todas as colunas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66f75e-be28-472e-b558-52cd7554cdee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "#Seleção de Todas as Colunas\n",
    "dataFrameCSV.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c94eaa-a15f-4c78-811b-53796c591f51",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: Select [column_n, ...]\n",
    "\n",
    "*- Selecão de todos os valores de colunas específicas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271554c2-6bca-4b3f-895b-3231e36999a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "#Seleção de Coluna Explícita\n",
    "dataFrameCSV.select('name', 'pirce').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b23899-1b3a-4f0a-a99d-cfdeb2b3ca61",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: Select TOP\\LIMIT \n",
    "\n",
    "*- Seleção de um Limite de Linhas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cc8b7-f2f7-401e-819b-d11b3a67c760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "# Seleção de 2 Linhas para todas as colunas\n",
    "dataFrameCSV.limit(2).show() \n",
    "\n",
    "# Selecão de 2 Linhas para 1 coluna explícita\n",
    "dataFrameCSV.select('name').limit(2).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344fc36-e0b8-4615-847e-7e06a78dea28",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: DISTINCT \n",
    "\n",
    "*- Seleção de Valores Distintos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f3918-77dc-4da7-8fac-c254f735f68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "# Efetua Seleção Distinta de Valor\n",
    "dataFrameCSV.select('kms_driven').distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b252f59-b8b2-4b23-b131-24d3c4534fe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: ORDER BY\n",
    "\n",
    "*- Ordernando colunas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bd6af-3680-41c4-979c-70dfa317441f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "# Usando função OrderBy\n",
    "\n",
    "dataFrameCSV.select('kms_driven').distinct().orderBy('kms_driven', ascending=True).limit(5).show() # OrderBy - Ascendente\n",
    "dataFrameCSV.select('kms_driven').distinct().orderBy('kms_driven', ascending=False).limit(5).show() # OrderBy - Descendente\n",
    "\n",
    "# Usando função Sort\n",
    "\n",
    "dataFrameCSV.select('kms_driven').distinct().sort(function.asc('kms_driven')).limit(5).show() # Sort - Ascendente\n",
    "dataFrameCSV.select('kms_driven').distinct().sort(function.desc('kms_driven')).limit(5).show() # Sort - Descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf88ff-b56a-41e4-92db-f0391a96b443",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: GROUP BY - COUNT\n",
    "\n",
    "*- Agrupando Valores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a67ac-ec2c-44fc-9c9c-19a447a6be56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "#Efetua Contagem dos Valores\n",
    "dataFrameCSV.groupBy('kms_driven').agg(function.count('name').alias(\"Quantidade\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b81ac0-5c2a-49a4-882e-8b7735dafd77",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: GROUP BY - COUNT (com Ordernação)\n",
    "\n",
    "*- Agrupando Valores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf784fbf-523a-4f4b-af21-2c99fc1bf218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "#Efetua Agrupamento dos Valores\n",
    "dataFrameCSV.groupBy('kms_driven').agg(function.count('name').alias(\"Quantidade\")).sort(function.desc(\"Quantidade\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f5cbf-42cb-442b-936e-a4b5914add35",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: CASE\n",
    "\n",
    "*- Coluna condicional*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb769b9-4eec-418a-a431-fa00b4b2d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "# Single Condition\n",
    "dataFrameCSV.withColumn(\n",
    "    'age_not_null',\n",
    "    function.when(dataFrameCSV.age.isNull(),0).otherwise(dataFrameCSV.age)\n",
    ").show(5)\n",
    "\n",
    "# Multiple Condition\n",
    "df_test = dataFrameCSV.select('kms_driven','owner').limit(10)\n",
    "\n",
    "df_test.withColumn(\n",
    "    'kms_driven',\n",
    "    function\\\n",
    "        .when((~dataFrameCSV[\"kms_driven\"].isin([\"Ahmedabad\",\"Delhi\"]) | (dataFrameCSV[\"kms_driven\"]==\"Delhi\")),0)\\\n",
    "        .otherwise(dataFrameCSV.kms_driven)\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311ec8d-235f-4bbd-8644-526b6466dda0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: FILTER\n",
    "\n",
    "*- Filtrando Dados*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecea75-e1e1-4b38-a4b5-f3b01f6f1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "\n",
    "# String (Filter Single Value)\n",
    "dataFrameCSV.select(\"name\").filter(dataFrameCSV.name.like('%Yamaha SZ 150%')).show()\n",
    "\n",
    "# Number (Filter Single Value)\n",
    "dataFrameCSV.filter(dataFrameCSV[\"power\"]==3.0).limit(3).show()\n",
    "\n",
    "# Number (Filter Single Value)\n",
    "dataFrameCSV.filter(dataFrameCSV[\"power\"]==3.0).limit(3).show()\n",
    "\n",
    "# Number (Filter Multiple Value - AND Operator)\n",
    "dataFrameCSV.filter((dataFrameCSV[\"power\"]==3.0) & (dataFrameCSV[\"brand\"]==110.0)).limit(3).show()\n",
    "\n",
    "# Number (Filter Multiple Value - OR Operator)\n",
    "dataFrameCSV.filter((dataFrameCSV[\"power\"]==5.0) | (dataFrameCSV[\"brand\"]==110.0)).limit(3).show()\n",
    "\n",
    "# List - (Filter Multipe Value IN)\n",
    "list_kms_driven = ['Ahmedabad', 'Bangalore']\n",
    "dataFrameCSV.filter(dataFrameCSV['kms_driven'].isin(list_kms_driven)).limit(3).show()\n",
    "\n",
    "# List - (Filter Multipe Value NOT IN)\n",
    "list_kms_driven = ['Ahmedabad', 'Bangalore', 'Delhi']\n",
    "dataFrameCSV.filter(~(dataFrameCSV['kms_driven'].isin(list_kms_driven))).limit(3).show()\n",
    "\n",
    "# List - (Filter NULL)\n",
    "dataFrameCSV.filter(dataFrameCSV['age'].isNull()).limit(3).show()\n",
    "\n",
    "# List - (Filter NOT NULL)\n",
    "dataFrameCSV.filter(dataFrameCSV['age'].isNotNull()).limit(3).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f826b-9618-4872-b5b2-6baa2aae3d5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: ROW_NUMBER\n",
    "\n",
    "*- Adicionando Indice de particionamento e ordernação de Dados*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e33a09-c9b6-4fab-b46e-f31bbcf754ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "df_test = dataFrameCSV.select('kms_driven','owner').limit(10)\n",
    "\n",
    "#Ordernação do índice ASCENDENTE\n",
    "\n",
    "df_test\\\n",
    ".withColumn(\n",
    "    \"row_number\", \n",
    "    function.row_number().over(Window.partitionBy(\"kms_driven\").orderBy(function.asc(\"owner\")))\n",
    ").select(\n",
    "    \"row_number\",\n",
    "    \"kms_driven\",\n",
    "    \"owner\"\n",
    ").show(1000)\n",
    "\n",
    "#Ordernação do índice DESCENDENTE\n",
    "\n",
    "df_test\\\n",
    ".withColumn(\n",
    "    \"row_number\", \n",
    "    function.row_number().over(Window.partitionBy(\"kms_driven\").orderBy(function.desc(\"owner\")))\n",
    ").select(\n",
    "    \"row_number\",\n",
    "    \"kms_driven\",\n",
    "    \"owner\"\n",
    ").show(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee14ca0-22ce-4582-81f4-92957c1e2da9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark: SQL\n",
    "*- Utilizando comando SQL Explícito para construção de Consultas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c20c27-3226-4a64-b37a-c9b311d08fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de Biblioteca\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "#Criação da Sessão Spark\n",
    "spark = pyspark.sql.SparkSession.builder.appName('session').getOrCreate()\n",
    "\n",
    "#Cria Dataset de test\n",
    "schema = StructType([\n",
    "StructField(\"name\", StringType(), True),\n",
    "StructField(\"pirce\", DoubleType(), True),\n",
    "StructField(\"kms_driven\", StringType(), True),\n",
    "StructField(\"owner\", DoubleType(), True),\n",
    "StructField(\"age\", IntegerType(), True),\n",
    "StructField(\"power\", DoubleType(), True),\n",
    "StructField(\"brand\", StringType(), True),])\n",
    "\n",
    "dataFrameCSV = spark.read.option('header',True).schema(schema).csv('./datasets/Bikes.csv')\n",
    "df_test = dataFrameCSV.select('kms_driven','owner').limit(10)\n",
    "\n",
    "#Cria View no Spark\n",
    "df_test.createOrReplaceTempView(\"df_test\")\n",
    "\n",
    "#Executa Consulta Usando SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    DATE_FORMAT(NOW(),'dd/MM/yyyy hh:ss') AS dt_atual, \n",
    "    kms_driven \n",
    "    FROM df_test\"\"\"\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
